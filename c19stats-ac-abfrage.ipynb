{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2020 Martin Holle. Alle Rechte vorbehalten. Lizensiert unter der MIT-Lizenz.\n",
    "\n",
    "# Covid-19 Statistics Aachen: Datenabfrage\n",
    "\n",
    "Abfrage der Daten von der Website der Städteregion Aachen und Speichern in einer Excel-Datei für die Datenübergabe an den nächsten Schritt, in dem die Daten aufbereitet werden.\n",
    "\n",
    "## Vorbereitungen\n",
    "\n",
    "- Benötigte Imports\n",
    "- Konfiguration aus zentraler `.ini`-Datei einlesen\n",
    "- Konfiguration und Instanzierung des Loggers\n",
    "- Globale Variablen definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import logging\n",
    "import configparser\n",
    "\n",
    "# Konfiguration einlesen\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Konfiguration des Loggings\n",
    "# - Die Logging-Ausgaben werden in der lokalen Datei covid-19-datenabfrage.log geschrieben\n",
    "# - Für die Ausgabe wird eine bestimmte Formatierung konfiguriert\n",
    "fhandler = logging.FileHandler(filename=config['Logging']['LogFileName'], mode='a')\n",
    "\n",
    "# TODO: Formatierung finalisieren (Tausendstel-Sekunden, Tag des Monats, 1. Zeichen des Levels)\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)-1.1s %(name)-20.20s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "\n",
    "# Instanzierung und Konfigurierung des Loggers\n",
    "log = logging.getLogger(\"datenabfrage\")\n",
    "log.addHandler(fhandler)\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "# Für die Zwischenspeicherung des eingelesenen HTML\n",
    "# - Wenn die Website in der aktuellen Session schon einmal abgefragt wurde, wird das Ergebnis\n",
    "#   der Abfrage in dieser Variablen gesichert\n",
    "# - Dies erleichtert die Entwicklung der nachfolgenden Verabeitungsschritte und führt nicht immer wieder zu\n",
    "#   neuen überflüssigen Abfragen der Website\n",
    "html_payload = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der existierenden Excel-Datei\n",
    "\n",
    "- Datei und Seite der Excel-Datei: Siehe `config.ini`\n",
    "- Einzulesende Spalten: \n",
    "  - **A**: Datum im Format 'DD.MM.'\n",
    "  - **B**: Akkumulierte Anzahl der Infektionen für gesamte Städteregion (inkl. Aachen) als Integerzahl\n",
    "  - **C**: Akkumulierte Anzahl der Infektionen für die Stadt Aachen als Integerzahl\n",
    "  - **D**: Anzahl neuer Todesfälle durch Covid-19 für gesamte Städteregion (inkl. Aachen) als Integerzahl\n",
    "  - **E**: Akkumulierte Anzahl der Todesfälle durch Covid-19 für gesamte Städteregion (inkl. Aachen) als Integerzahl \n",
    "  - **F**: Akkumulierte Anzahl der Genesenen für gesamte Städteregion (inkl. Aachen) als Integerzahl\n",
    "- Spalte A als Datum interpretieren\n",
    "- Die erste Zeile (Header) überspringen\n",
    "- Label der Spalten explizit setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uhrzeit</th>\n",
       "      <th>Summe</th>\n",
       "      <th>Summe Aachen</th>\n",
       "      <th>Summe Todesfälle</th>\n",
       "      <th>Summe genesen</th>\n",
       "      <th>Akute Fälle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2010</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>1900</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-10</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>999</td>\n",
       "      <td>100</td>\n",
       "      <td>1908</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-13</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>1002</td>\n",
       "      <td>100</td>\n",
       "      <td>1908</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-15</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1004</td>\n",
       "      <td>100</td>\n",
       "      <td>1909</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-17</th>\n",
       "      <td>09:45:00</td>\n",
       "      <td>2030</td>\n",
       "      <td>1007</td>\n",
       "      <td>100</td>\n",
       "      <td>1917</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-20</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2037</td>\n",
       "      <td>1008</td>\n",
       "      <td>100</td>\n",
       "      <td>1917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-22</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2044</td>\n",
       "      <td>1010</td>\n",
       "      <td>100</td>\n",
       "      <td>1920</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-24</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2058</td>\n",
       "      <td>1014</td>\n",
       "      <td>100</td>\n",
       "      <td>1922</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-27</th>\n",
       "      <td>09:45:00</td>\n",
       "      <td>2067</td>\n",
       "      <td>1016</td>\n",
       "      <td>100</td>\n",
       "      <td>1928</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-29</th>\n",
       "      <td>10:15:00</td>\n",
       "      <td>2076</td>\n",
       "      <td>1022</td>\n",
       "      <td>100</td>\n",
       "      <td>1937</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-31</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2095</td>\n",
       "      <td>1031</td>\n",
       "      <td>100</td>\n",
       "      <td>1942</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-03</th>\n",
       "      <td>09:45:00</td>\n",
       "      <td>2108</td>\n",
       "      <td>1040</td>\n",
       "      <td>100</td>\n",
       "      <td>1954</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-05</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>2139</td>\n",
       "      <td>1053</td>\n",
       "      <td>100</td>\n",
       "      <td>1958</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-07</th>\n",
       "      <td>10:45:00</td>\n",
       "      <td>2157</td>\n",
       "      <td>1060</td>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Uhrzeit  Summe  Summe Aachen  Summe Todesfälle  Summe genesen  \\\n",
       "Datum                                                                        \n",
       "2020-07-08  09:30:00   2010           999                99           1900   \n",
       "2020-07-10  09:30:00   2011           999               100           1908   \n",
       "2020-07-13  10:00:00   2021          1002               100           1908   \n",
       "2020-07-15  09:30:00   2025          1004               100           1909   \n",
       "2020-07-17  09:45:00   2030          1007               100           1917   \n",
       "2020-07-20  09:30:00   2037          1008               100           1917   \n",
       "2020-07-22  09:30:00   2044          1010               100           1920   \n",
       "2020-07-24  09:30:00   2058          1014               100           1922   \n",
       "2020-07-27  09:45:00   2067          1016               100           1928   \n",
       "2020-07-29  10:15:00   2076          1022               100           1937   \n",
       "2020-07-31  09:30:00   2095          1031               100           1942   \n",
       "2020-08-03  09:45:00   2108          1040               100           1954   \n",
       "2020-08-05  10:00:00   2139          1053               100           1958   \n",
       "2020-08-07  10:45:00   2157          1060               100           1975   \n",
       "\n",
       "            Akute Fälle  \n",
       "Datum                    \n",
       "2020-07-08           11  \n",
       "2020-07-10            3  \n",
       "2020-07-13           13  \n",
       "2020-07-15           16  \n",
       "2020-07-17           13  \n",
       "2020-07-20           20  \n",
       "2020-07-22           24  \n",
       "2020-07-24           36  \n",
       "2020-07-27           39  \n",
       "2020-07-29           39  \n",
       "2020-07-31           53  \n",
       "2020-08-03           54  \n",
       "2020-08-05           81  \n",
       "2020-08-07           82  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['Uhrzeit', 'Summe', 'Summe Aachen', 'Summe Todesfälle', 'Summe genesen', 'Akute Fälle' ]\n",
    "\n",
    "try:\n",
    "    c19_cases = pd.read_excel(config['Rohdaten']['FileName'], \n",
    "                              sheet_name=config['Rohdaten']['SheetName'], \n",
    "                              index_col=0,\n",
    "                              parse_dates=[0],\n",
    "                              skiprows=[],\n",
    "                              names=col_names)\n",
    "except FileNotFoundError as err: \n",
    "    log.warning('Error during pd.read_excel(): {0}'.format(err))\n",
    "    # Leere DataFrame für den Start erzeugen\n",
    "    c19_cases = pd.DataFrame(columns=col_names, index=pd.DatetimeIndex([], name='Datum'))\n",
    "    \n",
    "c19_cases.tail(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenabfrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionen für die Datenabfrage und Extraktion der Rohtexte\n",
    "\n",
    "- `robot_access_allowed()` - Via robots.txt prüfen, ob die Website durch ein Skript abgefragt und verabeitet werden darf\n",
    "- `gather_html()` - Website abfragen und HTML zurückliefern\n",
    "- `gather_text()` - Relevante Texte aus dem von der Website geliefertem HTML extrahieren und zurückliefern\n",
    "\n",
    "*<u>Anmerkungen:</u>  \n",
    "Die Website der Städteregion Aachen verwendet keine `robots.txt`, damit wäre die Funktion `robot_access_allowed()` eigentlich überflüssig. Hier ist sie nur der Vollständigkeit halber definiert und nicht ausimplementiert.*\n",
    "\n",
    "*Leider unterscheidet sich die HTML-Struktur der aktuellen Meldungen von der des Meldungsarchivs so stark, dass schon an dieser Stelle eine Differenzierung aufgrund des Textes und nicht nur der HTML-Struktur erfolgen muss. Daher wurde das Argument `kind` zur Funktion `gather_html()` hinzugefügt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_user_agent = config['Rohdaten']['UserAgent']\n",
    "\n",
    "def robot_access_allowed(url: str, user_agent: str=default_user_agent) -> bool:\n",
    "    \"\"\"Request robots.txt. If exists, parse robots.txt and return True if scraping by this script is allowed.\"\"\"\n",
    "    \n",
    "    log.debug(\"access_allowed(\" + url + \", \" + user_agent + \")\")\n",
    "    \n",
    "    headers = { 'user-agent': user_agent }\n",
    "    \n",
    "    # Extract root of the website's URL\n",
    "    \n",
    "    # Request robots.txt from root of the website\n",
    "    \n",
    "    # If robots.txt exist, parse content of the file\n",
    "    \n",
    "    return True\n",
    "\n",
    "def gather_html(url: str, user_agent: str=default_user_agent) -> str:\n",
    "    \"\"\"Request Website from <url> and return the HTML delivered by the Website as text.\"\"\"\n",
    "\n",
    "    log.debug(\"gather_html(\" + url + \", \" + user_agent + \")\")\n",
    "    \n",
    "    # Website abfragen\n",
    "    headers = { 'user-agent': user_agent }\n",
    "    page = requests.get(url)\n",
    "    log.debug(\"gather_html/page.status_code: %d\", page.status_code)\n",
    "    for key, val in page.headers.items():\n",
    "        log.debug(\"gather_html/page.header(%s): %s\", key, val)   \n",
    "    if page.status_code == requests.codes.ALL_OK: # Alles ok\n",
    "        return page.text\n",
    "        \n",
    "    return None\n",
    "\n",
    "def gather_text(html_text: str) -> []:\n",
    "    \"\"\"\n",
    "    Extract relevant text content from <html_text> and return dictionary with extracted text for 'Header', 'Abstract', 'Main'.\n",
    "    \"\"\"\n",
    "\n",
    "    log.debug(f\"gather_text(%d chars)\", len(html_text))\n",
    "\n",
    "    records = []\n",
    "       \n",
    "    # Parser instanzieren\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    # Relevante Objekte aus geliefertem HTML extrahieren\n",
    "    # - Header\n",
    "    # - Abstract (existiert nur für die aktuellen Meldungen, nicht im Meldungsarchiv)\n",
    "    # - Main\n",
    "    divs = soup.select('div.mid-col article > div.textcontent > div')\n",
    "    for div in divs:\n",
    "        # Header erkennen: Nun wenn dieser gefunden wird, macht es Sinn, nachfolgend nach \n",
    "        # Abstract und Haupttext zu suchen\n",
    "        header = div.select('h2')\n",
    "        if header:\n",
    "            # Header: Text extrahieren\n",
    "            header_text = next(header[0].stripped_strings)\n",
    "\n",
    "            # Abstract: Text extrahieren\n",
    "            abstract = div.select('div > div > ul > li')\n",
    "            abstract_text = ''\n",
    "            for a in abstract:\n",
    "                for tx in a.stripped_strings:\n",
    "                    abstract_text += tx\n",
    "            \n",
    "            # Haupttext extrahieren\n",
    "            main = div.select('div > p')\n",
    "            main_text = ''\n",
    "            for tx in main[0].stripped_strings:\n",
    "                main_text += tx\n",
    "\n",
    "            # Neuen Eintrag mit den extahierten Texten hinzufügen \n",
    "            records.append({'Header': header_text, 'Abstract': abstract_text, 'Main': main_text })\n",
    "                        \n",
    "    log.debug(\"gather_text: %d records extracted from HTML\", len(records))\n",
    "    \n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionen für die Extraktion der Falldaten aus den Rohtexten\n",
    "\n",
    "In der ersten Version erfolgt die Extraktion der Daten aus den Texten mit Hilfe regulärer Ausdrücke:\n",
    "\n",
    "- Datum/Uhrzeit der Meldung wird aus dem `Header` extrahiert.\n",
    "- Die eigentlichen Daten werden zweimal extrahiert: Einmal aus dem `Abstract` und zum zweiten Mal aus dem `Main`-Text. \n",
    "- Falls sowohl `Abstract` als auch `Main` eingelesen wurden, werden anschließend die extrahierten Daten miteinander verglichen. Nur wenn sie übereinstimmen, wird der Datensatz übernommen.\n",
    "\n",
    "Die für das Parsen der eingelesenen Texte verwendeten regulären Ausdrücke versuchen einerseits, auf Nummer sicher zu gehen, um die richtigen Textstellen für das Einlesen der Zahlen zu treffen, und andererseits einige Freiheitsgrade zuzulassen: \n",
    "\n",
    "- Leerzeichen und andere \"White Spaces\" werden von Menschen hin und wieder vergesssen oder mehrfach eingegeben\n",
    "- Textvariationen kommen vor, in denen einzelne Wörter nicht erscheinen oder hinzugefügt werden\n",
    "- Manchmal werden einzelne Buchstaben weggelassen, ohne dass dies ein Schreibfehler wäre\n",
    "- Und natürlich kommen auch Schreibfehler vor \n",
    "\n",
    "Die regulären Ausdrücke sind dadurch relativ unübersichtlich geworden und berücksichtigen dennoch nicht alle Situationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsMeta():\n",
    "    \"\"\"Value class for meta data of news entry.\"\"\"\n",
    "    pass\n",
    "\n",
    "class CaseFigures():\n",
    "    \"\"\"Value class for case figures, extracted from the news entries.\"\"\"\n",
    "    pass\n",
    "\n",
    "def parse_header(header: str) -> NewsMeta:\n",
    "    \"\"\"\n",
    "    Analyse <header> of the news and return date and time of news or None. \n",
    "    \n",
    "    The <header> is expected to have the following format:\n",
    "    \n",
    "    'Aktuelle Lage Stadt und StädteRegion Aachen zum Corona-Virus; Montag, 22. Juni, 10:00 Uhr'\n",
    "    \n",
    "    Variables weekday name, date, and time will be extracted from header. Year assumed to be 2020.\n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "    header - extracted raw text of header\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    None - if no matching header found\n",
    "    NewsMeta(weekday_name, day_of_month, month_name, hour, minutes, date, time, datetime)\n",
    "    \"\"\"\n",
    "    \n",
    "    monthnames = [ \"Januar\", \"Februar\", \"März\", \"April\", \"Mai\", \"Juni\", \"Juli\", \"August\", \"September\", \n",
    "                  \"Oktober\", \"November\", \"Dezember\" ]\n",
    "    \n",
    "    log.debug(\"parse_header(\" + header[:40] + \"...)\")\n",
    "    \n",
    "    pattern = r\"^Aktuelle Lage Stadt und StädteRegion Aachen zum Corona-Virus;\\s*\" + \\\n",
    "    r\"(Montag|Dienstag|Mittwoch|Donnerstag|Freitag|Samstag|Sonntag),\\s*\" + \\\n",
    "    r\"([0-9]{1,2})\\.\\s*(Januar|Februar|März|April|Mai|Juni|Juli|August|September|Oktober|November|Dezember),\\s*\" + \\\n",
    "    r\"([0-9]{1,2}):([0-9]{2})\\s*Uhr.*$\"\n",
    "        \n",
    "    match = re.search(pattern, header)\n",
    "    if match:\n",
    "        meta = NewsMeta()\n",
    "        try:\n",
    "            meta.weekday_name = match.group(1)\n",
    "            meta.day_of_month = int(match.group(2))\n",
    "            meta.month_name = match.group(3)\n",
    "            meta.hour = int(match.group(4))\n",
    "            meta.minutes = int(match.group(5))\n",
    "            meta.date = date(2020, monthnames.index(meta.month_name) + 1, meta.day_of_month)\n",
    "            meta.time = time(meta.hour, meta.minutes)\n",
    "            meta.datetime = datetime.combine(meta.date, meta.time)\n",
    "            log.debug(f\"parse_header/meta.weekday: %s\", meta.weekday_name)        \n",
    "            log.debug(f\"parse_header/meta.day_of_month: %d\", meta.day_of_month)        \n",
    "            log.debug(f\"parse_header/meta.month_name: %s\", meta.month_name)        \n",
    "            log.debug(f\"parse_header/meta.hour: %d\", meta.hour)        \n",
    "            log.debug(f\"parse_header/meta.minutes: %d\", meta.minutes)        \n",
    "            log.debug(f\"parse_header/meta.date: %s\", str(meta.date))        \n",
    "            log.debug(f\"parse_header/meta.time: %s\", str(meta.time))\n",
    "            log.debug(f\"parse_header/meta.datetime: %s\", str(meta.datetime))\n",
    "            return meta\n",
    "        except:\n",
    "            log.warning(\"parse_header() failed parsing news header [1]\")\n",
    "            return None\n",
    "    else: \n",
    "        log.warning(\"parse_header() failed parsing news header [2]\")\n",
    "        return None\n",
    "\n",
    "def parse_cases(kind: str, text: str, pattern_total: str, pattern_recovered: str, pattern_deaths: str, \n",
    "                pattern_active: str) -> CaseFigures:\n",
    "    \"\"\"\n",
    "    Analyse <abstract> or <main> text of the news and return Covid-19 case numbers included therein. \n",
    "  \n",
    "    Parameters:\n",
    "    ===========\n",
    "    kind\n",
    "    text\n",
    "    pattern_total\n",
    "    pattern_recovered\n",
    "    pattern_deaths\n",
    "    pattern_active\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    None - if text could not be parsed successfully\n",
    "    CaseFigures(total, total_AC, recovered, deaths, active)\n",
    "    \"\"\"\n",
    "    \n",
    "    log.debug(f\"parse_cases(%s, %s)\", kind, text[:80])\n",
    "\n",
    "    figures = CaseFigures()\n",
    "    \n",
    "    # Summe der Corona-Fälle extrahieren\n",
    "    match = re.search(pattern_total, text)\n",
    "    if match:\n",
    "        try:\n",
    "            figures.total = int(match.group(1))\n",
    "            figures.total_AC = int(match.group(2))\n",
    "            log.debug(f\"parse_cases/figures.total: %d\", figures.total)        \n",
    "            log.debug(f\"parse_cases/figures.total_AC: %d\", figures.total_AC)        \n",
    "        except:\n",
    "            log.warning(f\"parse_cases(%s) failed [1]\", kind)\n",
    "            return None\n",
    "    else: \n",
    "        log.warning(f\"parse_cases(%s) failed [2]\", kind)\n",
    "        return None\n",
    "    \n",
    "    # Summe der wieder Genesenen extrahieren\n",
    "    match = re.search(pattern_recovered, text)\n",
    "    if match:\n",
    "        try:\n",
    "            figures.recovered = int(match.group(1))\n",
    "            log.debug(f\"parse_cases/figures.recovered: %d\", figures.recovered)        \n",
    "        except:\n",
    "            log.warning(f\"parse_cases(%s) failed [3]\", kind)\n",
    "            return None\n",
    "    else: \n",
    "        log.warning(f\"parse_cases(%s) failed [4]\", kind)\n",
    "        return None\n",
    "    \n",
    "    # Summe der Corona-Toten extrahieren\n",
    "    match = re.search(pattern_deaths, text)\n",
    "    if match:\n",
    "        try:\n",
    "            figures.deaths = int(match.group(1))\n",
    "            log.debug(f\"parse_cases/figures.deaths: %d\", figures.deaths)        \n",
    "        except:\n",
    "            log.warning(f\"parse_cases(%s) failed [5]\", kind)\n",
    "            return None\n",
    "    else: \n",
    "        log.warning(f\"parse_cases(%s) failed [6]\", kind)\n",
    "        return None\n",
    "    \n",
    "    # Anzahl der aktiven Infektionen extrahieren\n",
    "    match = re.search(pattern_active, text)\n",
    "    if match:\n",
    "        try:\n",
    "            figures.active = int(match.group(1))\n",
    "            log.debug(f\"parse_cases/figures.active: %d\", figures.active)        \n",
    "        except:\n",
    "            log.warning(f\"parse_cases(%s) failed [7]\", kind)\n",
    "            return None\n",
    "    else: \n",
    "        log.warning(f\"parse_cases(%s) failed [8]: %s\", kind, text)\n",
    "        return None\n",
    "\n",
    "    return figures\n",
    "\n",
    "def parse_abstract(abstract: str) -> CaseFigures:\n",
    "    \"\"\"\n",
    "    Analyse <abstract> of the news and return Covid-19 case numbers included in abstract. \n",
    "\n",
    "    The relevant area of the <abstract> is expected to have the following format:\n",
    "    \n",
    "    'Aktuell 1999 bestätigte Coronafälle in der StädteRegion Aachen (davon 994 in der Stadt Aachen). '\n",
    "    '1880 ehemals positiv auf das Corona-Virus getestete Personen sind inzwischen wieder gesund. '\n",
    "    'Bislang 98 Todesfälle. Damit aktuell 21 nachgewiesene Infizierte.'\n",
    "    \n",
    "    Values will be extracted from abstract text. \n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "    abstract - extracted raw text of abstract\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    None - if abstract could not be parsed successfully\n",
    "    CaseFigures(total, total_AC, recovered, deaths, active)\n",
    "    \"\"\"\n",
    "    \n",
    "    log.debug(\"parse_abstract(\" + abstract[:40] + \"...)\")\n",
    "    \n",
    "    pattern_total = r\"^Aktuell\\s*([0-9]{1,6})\\s*bestätigte\\s*Coronafälle\\s*in\\s*der\\s*StädteRegion\\s*\" + \\\n",
    "    r\"(?:Aachen)?\\s*[(]davon\\s*([0-9]{1,6})\\s*in\\s*der\\s*Stadt\\s*Aachen[)].*\"\n",
    "    pattern_recovered = r\"([0-9]{1,6})\\s*ehemals\\s*positiv\\s*auf\\s*das\\s*Corona-Virus\\s*getestete\\s*\" + \\\n",
    "    r\"Personen\\s*sind\\s*inzwischen\\s*wieder\\s*gesund.*\"\n",
    "    pattern_deaths = r\"Bislang\\s*([0-9]{1,6})\\s*Todesfälle.*\"\n",
    "    pattern_active = r\"Damit\\s*aktuell\\s*([0-9]{1,6})\\s*nachgewiesene?\\s*Infizie.*\"\n",
    "        \n",
    "    return parse_cases(\"Abstract\", abstract, pattern_total, pattern_recovered, pattern_deaths, pattern_active)\n",
    "\n",
    "def parse_main(main: str) -> CaseFigures:\n",
    "    \"\"\"\n",
    "    Analyse <main> text of the news and return Covid-19 case numbers included in main text. \n",
    "    \n",
    "    The relevant area of the <abstract> is expected to have the following format:\n",
    "      \n",
    "    'Es gibt insgesamt in der StädteRegion [nunmehr] 1997 positive Fälle, davon 992 in der Stadt Aachen'\n",
    "    '1876 ehemals positiv auf das Corona-Virus getestete Personen sind inzwischen wieder gesund'\n",
    "    'Die Zahl der gemeldeten Todesfälle liegt [nach wie vor] bei 98'\n",
    "    'Damit sind aktuell 23 Menschen in der StädteRegion nachgewiesen infiziert'\n",
    "\n",
    "    Parameters:\n",
    "    ===========\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    None - if abstract could not be parsed successfully\n",
    "    CaseFigures(total, total_AC, recovered, deaths, active)\n",
    "    \"\"\"\n",
    "    log.debug(\"parse_main(\" + main[:40] + \"...)\")\n",
    "\n",
    "    pattern_total = r\"Es\\s*gibt\\s*insgesamt\\s*in\\s*der\\s*StädteRegion\\s*(?:nunmehr)?\\s*([0-9]{1,6})\\s*\" + \\\n",
    "    r\"positive\\s*Fälle,\\s*davon\\s*([0-9]{1,6})\\s*in\\s*der\\s*Stadt\\s*Aachen\"\n",
    "    pattern_recovered = r\"([0-9]{1,6})\\s*ehemals\\s*positiv\\s*auf\\s*das\\s*Corona-Virus\\s*getestete\\s*\" + \\\n",
    "    r\"Personen\\s*sind\\s*inzwischen\\s*wieder\\s*gesund\"\n",
    "    pattern_deaths = r\"Die\\s*Zahl\\s*der\\s*gemeldeten\\s*Todesfälle\\s*liegt\\s*(?:nach\\s*wie\\s*vor)?\\s*\" + \\\n",
    "    r\"bei\\s*([0-9]{1,6})\"\n",
    "    pattern_active = r\"Damit\\s*sind\\s*aktuell\\s*([0-9]{1,6})\\s*Menschen\\s*in\\s*der\\s*StädteRegion\\s*\" + \\\n",
    "    r\"(?:Aachen)?\\s*nachgewiesen\\s*infiziert\"\n",
    "    \n",
    "    return parse_cases(\"Main\", main, pattern_total, pattern_recovered, pattern_deaths, pattern_active)\n",
    "\n",
    "def checked_data(meta: NewsMeta, fig_abstract: CaseFigures, fig_main: CaseFigures) -> []:\n",
    "    \"\"\"\n",
    "    Check extracted data for consistency and return valid figures or None.\n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    [ Date, Time, Total, Total_AC, Deaths, Recovered, Active ] - Array w/ read Covid-19 numbers\n",
    "    None - if consistency check fails\n",
    "    \"\"\"\n",
    "    \n",
    "    if meta != None: \n",
    "        # Der Header konnte erfolgreich analysiert werden\n",
    "        a, m = fig_abstract, fig_main\n",
    "        if (a != None) and (m != None): \n",
    "            # Sowohl Abstract als auch Main konnten erfolgreich analysiert werden\n",
    "            if (m.total == a.total) and (m.deaths == a.deaths) and (m.recovered == a.recovered) and \\\n",
    "               (m.active == a.active):\n",
    "                # Die eingelesenen Zahlen aus Abstract und Main stimmmen überein\n",
    "                if m.active == 0:\n",
    "                    # Die Anzahl aktiver Fälle war nicht explizit angegeben und wird stattdessen berechnet\n",
    "                    m.active = m.total - m.deaths - m.recovered\n",
    "                if m.total - m.deaths - m.recovered == m.active:\n",
    "                    # Die eingelesenen Daten haben die Konsistenzprüfung bestanden\n",
    "                    return [ meta.date, meta.time, m.total, m.total_AC, m.deaths, m.recovered, m.active ]\n",
    "                else:\n",
    "                    log.warning('Data consistency error: (1) Main and Abstract found. Inconsistent figures read.')\n",
    "                    return None\n",
    "        elif m != None: \n",
    "            # Mindestens Main konnte erfolgreich analysiert werden\n",
    "            if m.active == 0:\n",
    "                # Die Anzahl aktiver Fälle war nicht explizit angegeben und wird stattdessen berechnet\n",
    "                m.active = m.total - m.deaths - m.recovered\n",
    "            if m.total - m.deaths - m.recovered == m.active:\n",
    "                # Die eingelesenen Daten haben die Konsistenzprüfung bestanden\n",
    "                return [ meta.date, meta.time, m.total, m.total_AC, m.deaths, m.recovered, m.active ]\n",
    "            else:\n",
    "                log.warning('Data onsistency error: (2) Only Main found. Inconsistent figures read. ')\n",
    "                return None\n",
    "    else:\n",
    "        log.warning('Data consistency error: (3) Header not found.')\n",
    "        return None\n",
    "\n",
    "def fill_dataframe_from_text(text_records: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyse <text_records> and return Pandas dataframe with parsed Covid-19 case numbers. \n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "    text_records\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    pd.DataFrame - \n",
    "    \"\"\"\n",
    "    \n",
    "    log.debug(f\"fill_dataframe_from_text(%d records)\", len(text_records))\n",
    "\n",
    "    figures = [] # Zwischenspeicherung der eingelesenen Zahlen\n",
    "    dates = [] # Zwischenspeicherung der Datumsangaben\n",
    "    \n",
    "    for tr in text_records:\n",
    "        meta = parse_header(tr['Header'])\n",
    "        fig_abstract = parse_abstract(tr['Abstract'])\n",
    "        fig_main = parse_main(tr['Main'])\n",
    "        \n",
    "        rec = checked_data(meta, fig_abstract, fig_main)\n",
    "        if rec:\n",
    "            dates.append(rec[0])\n",
    "            figures.append(rec[1:])\n",
    "            \n",
    "\n",
    "    if figures.count:\n",
    "        cols = ['Uhrzeit', 'Summe', 'Summe Aachen', 'Summe Todesfälle', 'Summe genesen', 'Akute Fälle' ]\n",
    "        index = pd.DatetimeIndex(dates, name='Datum')\n",
    "        df = pd.DataFrame(np.array(figures), columns=cols, index=index).sort_index()\n",
    "        return df\n",
    "    \n",
    "    return pd.DataFrame() # Leer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenabfrage durchführen\n",
    "\n",
    "1. Datum des letzten Datensatzes in der Excel-Datei ermitteln und mit aktuellem Datum vergleichen. \n",
    "2. Wenn mindestens 1 Tag seit der letzten Datenabfrage vergangen ist, neue Abfrage durchführen.\n",
    "3. Von der Website gelieferte Rohtexte auswerten und Fallzahlen extrahieren\n",
    "4. Extrahierte Fallzahlen auf Konsistenz prüfen\n",
    "5. Geprüfte Fallzahlen zu neuem DataFrame hinzufügen\n",
    "6. Den neuen mit dem existierendem DataFrame zusammenführen\n",
    "7. Zusammengeführte Daten speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "new_request = (c19_cases.size == 0) or \\\n",
    "    (date.today() >= (date.fromtimestamp(c19_cases.index.max().timestamp()) + timedelta(days=1)))\n",
    "\n",
    "if new_request:\n",
    "    log.info(\"New request initiated\")\n",
    "    if not html_payload:\n",
    "        url = config['Rohdaten']['SourceURLDefault']\n",
    "        if robot_access_allowed(url):\n",
    "            html_payload = gather_html(url)\n",
    "\n",
    "    if html_payload:\n",
    "        records = gather_text(html_payload)\n",
    "\n",
    "    if records.count:\n",
    "        new_cases = fill_dataframe_from_text(records)\n",
    "\n",
    "    if not new_cases.empty:\n",
    "        # Nur Zeilen mit neuerem Datum hinzufügen\n",
    "        merged_cases = pd.concat([c19_cases, new_cases[new_cases.index > c19_cases.index[-1]]], join='outer')\n",
    "\n",
    "    merged_cases.to_excel(config['Rohdaten']['FileName'], \n",
    "                          sheet_name=config['Rohdaten']['SheetName'], index_label='Datum')\n",
    "    \n",
    "    merged_cases.tail(10)\n",
    "else:\n",
    "    log.info(\"No new request required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
