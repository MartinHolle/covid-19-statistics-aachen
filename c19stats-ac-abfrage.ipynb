{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid-19 Statistics Aachen: Datenabfrage\n",
    "\n",
    "Abfrage der Daten von der Website der StädteRegion Aachen und Speichern in einer Excel-Datei für die Datenübergabe an den nächsten Schritt, in dem die Daten aufbereitet werden.\n",
    "\n",
    "## Vorbereitungen\n",
    "- Benötigte Imports\n",
    "- Konfiguration aus zentrale .ini-Datei einlesen\n",
    "- Konfiguration und Instanzierung des Loggers\n",
    "- Globale Variablen definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import logging\n",
    "import configparser\n",
    "\n",
    "# Konfiguration einlesen\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Konfiguration des Loggings\n",
    "# - Die Logging-Ausgaben werden in der lokalen Datei covid-19-datenabfrage.log geschrieben\n",
    "# - Für die Ausgabe wird eine bestimmte Formatierung konfiguriert\n",
    "fhandler = logging.FileHandler(filename=config['Logging']['LogFileName'], mode='a')\n",
    "\n",
    "# TODO: Formatierung finalisieren (Tausendstel-Sekunden, Tag des Monats, 1. Zeichen des Levels)\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)-1.1s %(name)-20.20s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "\n",
    "# Instanzierung und Konfigurierung des Loggers\n",
    "log = logging.getLogger(\"datenabfrage\")\n",
    "log.addHandler(fhandler)\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "# Für die Zwischenspeicherung des eingelesenen HTML\n",
    "# - Wenn die Website in der aktuellen Session schon einmal abgefragt wurde, wird das Ergebnis\n",
    "#   der Abfrage in dieser Variablen gesichert\n",
    "# - Dies erleichtert die Entwicklung der nachfolgenden Verabeitungsschritte und führt nicht immer wieder zu\n",
    "#   neuen überflüssigen Abfragen der Website\n",
    "html_payload = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der existierenden Excel-Datei\n",
    "- Datei: Siehe `config.ini`\n",
    "- Seite: Siehe `config.ini`\n",
    "- Einzulesende Spalten: \n",
    "  - **A**: Datum im Format 'DD.MM.'\n",
    "  - **B**: Akkumulierte Anzahl der Infektionen für gesamte Städteregion (inkl. Aachen) als Integerzahl\n",
    "  - **C**: Akkumulierte Anzahl der Infektionen für die Stadt Aachen als Integerzahl\n",
    "  - **D**: Anzahl neuer Todesfälle durch Covid-19 für gesamte Städteregion (inkl. Aachen) als Integerzahl\n",
    "  - **E**: Akkumulierte Anzahl der Todesfälle durch Covid-19 für gesamte Städteregion (inkl. Aachen) als Integerzahl \n",
    "  - **F**: Akkumulierte Anzahl der Genesenen für gesamte Städteregion (inkl. Aachen) als Integerzahl\n",
    "- Spaltentypen: Spalte A als Datum interpretieren\n",
    "- Die erste Zeile (Header) überspringen\n",
    "- Label der Spalten explizit setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uhrzeit</th>\n",
       "      <th>Summe</th>\n",
       "      <th>Summe Aachen</th>\n",
       "      <th>Summe Todesfälle</th>\n",
       "      <th>Summe genesen</th>\n",
       "      <th>Akute Fälle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-09</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-10</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>61</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-11</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>63</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-12</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-13</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>85</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-14</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-15</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>155</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-16</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>169</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-17</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>211</td>\n",
       "      <td>100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-18</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>273</td>\n",
       "      <td>130</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-19</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>334</td>\n",
       "      <td>161</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-20</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>405</td>\n",
       "      <td>192</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-21</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>443</td>\n",
       "      <td>209</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>516</td>\n",
       "      <td>246</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-23</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>530</td>\n",
       "      <td>249</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-24</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>540</td>\n",
       "      <td>261</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>618</td>\n",
       "      <td>315</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>694</td>\n",
       "      <td>354</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-27</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>746</td>\n",
       "      <td>376</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-28</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>787</td>\n",
       "      <td>399</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-29</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>824</td>\n",
       "      <td>407</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>863</td>\n",
       "      <td>429</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>920</td>\n",
       "      <td>463</td>\n",
       "      <td>15.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>980</td>\n",
       "      <td>495</td>\n",
       "      <td>16.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-02</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1081</td>\n",
       "      <td>555</td>\n",
       "      <td>21.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-03</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1155</td>\n",
       "      <td>602</td>\n",
       "      <td>21.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-04</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1213</td>\n",
       "      <td>633</td>\n",
       "      <td>27.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-05</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1259</td>\n",
       "      <td>651</td>\n",
       "      <td>27.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1272</td>\n",
       "      <td>658</td>\n",
       "      <td>27.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1295</td>\n",
       "      <td>674</td>\n",
       "      <td>35.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-26</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1960</td>\n",
       "      <td>971</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1839.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-27</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1962</td>\n",
       "      <td>973</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-28</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1964</td>\n",
       "      <td>975</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-29</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1967</td>\n",
       "      <td>978</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-02</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1971</td>\n",
       "      <td>982</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-03</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>1972</td>\n",
       "      <td>983</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1858.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1975</td>\n",
       "      <td>983</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1859.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-05</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>1976</td>\n",
       "      <td>983</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1859.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1979</td>\n",
       "      <td>982</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-09</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>1979</td>\n",
       "      <td>982</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1863.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-10</th>\n",
       "      <td>10:30:00</td>\n",
       "      <td>1980</td>\n",
       "      <td>983</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-12</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1982</td>\n",
       "      <td>984</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-15</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1982</td>\n",
       "      <td>984</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-17</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1985</td>\n",
       "      <td>985</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-19</th>\n",
       "      <td>10:30:00</td>\n",
       "      <td>1991</td>\n",
       "      <td>988</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-22</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>1994</td>\n",
       "      <td>989</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-24</th>\n",
       "      <td>10:15:00</td>\n",
       "      <td>1997</td>\n",
       "      <td>992</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-26</th>\n",
       "      <td>09:45:00</td>\n",
       "      <td>1999</td>\n",
       "      <td>994</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2001</td>\n",
       "      <td>996</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>998</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-03</th>\n",
       "      <td>09:45:00</td>\n",
       "      <td>2009</td>\n",
       "      <td>999</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2010</td>\n",
       "      <td>999</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2010</td>\n",
       "      <td>999</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-10</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>999</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-13</th>\n",
       "      <td>10:00:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>1002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-15</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1909.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-17</th>\n",
       "      <td>09:45:00</td>\n",
       "      <td>2030</td>\n",
       "      <td>1007</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-20</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2037</td>\n",
       "      <td>1008</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-22</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2044</td>\n",
       "      <td>1010</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-24</th>\n",
       "      <td>09:30:00</td>\n",
       "      <td>2058</td>\n",
       "      <td>1014</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Uhrzeit  Summe  Summe Aachen  Summe Todesfälle  Summe genesen  \\\n",
       "Datum                                                                        \n",
       "2020-03-09  10:00:00     58            20               NaN            NaN   \n",
       "2020-03-10  10:00:00     61            21               NaN            6.0   \n",
       "2020-03-11  10:00:00     63            22               NaN            NaN   \n",
       "2020-03-12  10:00:00     70            25               NaN            NaN   \n",
       "2020-03-13  10:00:00     85            34               NaN           27.0   \n",
       "2020-03-14  10:00:00    100            40               NaN           28.0   \n",
       "2020-03-15  10:00:00    155            75               NaN            NaN   \n",
       "2020-03-16  10:00:00    169            85               NaN           33.0   \n",
       "2020-03-17  10:00:00    211           100               2.0            NaN   \n",
       "2020-03-18  10:00:00    273           130               4.0            NaN   \n",
       "2020-03-19  10:00:00    334           161               4.0            NaN   \n",
       "2020-03-20  10:00:00    405           192               5.0            NaN   \n",
       "2020-03-21  10:00:00    443           209               5.0            NaN   \n",
       "2020-03-22  10:00:00    516           246               5.0            NaN   \n",
       "2020-03-23  10:00:00    530           249               6.0            NaN   \n",
       "2020-03-24  10:00:00    540           261               7.0            NaN   \n",
       "2020-03-25  10:00:00    618           315               8.0            NaN   \n",
       "2020-03-26  10:00:00    694           354               9.0            NaN   \n",
       "2020-03-27  10:00:00    746           376              14.0            NaN   \n",
       "2020-03-28  10:00:00    787           399              14.0            NaN   \n",
       "2020-03-29  10:00:00    824           407              14.0            NaN   \n",
       "2020-03-30  10:00:00    863           429              14.0            NaN   \n",
       "2020-03-31  10:00:00    920           463              15.0          322.0   \n",
       "2020-04-01  10:00:00    980           495              16.0          364.0   \n",
       "2020-04-02  10:00:00   1081           555              21.0          435.0   \n",
       "2020-04-03  10:00:00   1155           602              21.0          494.0   \n",
       "2020-04-04  10:00:00   1213           633              27.0          560.0   \n",
       "2020-04-05  10:00:00   1259           651              27.0          578.0   \n",
       "2020-04-06  10:00:00   1272           658              27.0          595.0   \n",
       "2020-04-07  10:00:00   1295           674              35.0          662.0   \n",
       "...              ...    ...           ...               ...            ...   \n",
       "2020-05-26  10:00:00   1960           971              91.0         1839.0   \n",
       "2020-05-27  10:00:00   1962           973              92.0         1846.0   \n",
       "2020-05-28  10:00:00   1964           975              92.0         1849.0   \n",
       "2020-05-29  10:00:00   1967           978              93.0         1850.0   \n",
       "2020-06-02  10:00:00   1971           982              93.0         1856.0   \n",
       "2020-06-03  09:30:00   1972           983              94.0         1858.0   \n",
       "2020-06-04  10:00:00   1975           983              94.0         1859.0   \n",
       "2020-06-05  09:30:00   1976           983              94.0         1859.0   \n",
       "2020-06-08  10:00:00   1979           982              94.0         1862.0   \n",
       "2020-06-09  09:30:00   1979           982              94.0         1863.0   \n",
       "2020-06-10  10:30:00   1980           983              95.0         1865.0   \n",
       "2020-06-12  10:00:00   1982           984              95.0         1869.0   \n",
       "2020-06-15  10:00:00   1982           984              95.0         1871.0   \n",
       "2020-06-17  10:00:00   1985           985              95.0         1871.0   \n",
       "2020-06-19  10:30:00   1991           988              97.0         1873.0   \n",
       "2020-06-22  10:00:00   1994           989              97.0         1875.0   \n",
       "2020-06-24  10:15:00   1997           992              98.0         1876.0   \n",
       "2020-06-26  09:45:00   1999           994              98.0         1880.0   \n",
       "2020-06-29  09:30:00   2001           996              98.0         1883.0   \n",
       "2020-07-01  09:30:00   2004           998              98.0         1890.0   \n",
       "2020-07-03  09:45:00   2009           999              98.0         1898.0   \n",
       "2020-07-06  09:30:00   2010           999              98.0         1900.0   \n",
       "2020-07-08  09:30:00   2010           999              99.0         1900.0   \n",
       "2020-07-10  09:30:00   2011           999             100.0         1908.0   \n",
       "2020-07-13  10:00:00   2021          1002             100.0         1908.0   \n",
       "2020-07-15  09:30:00   2025          1004             100.0         1909.0   \n",
       "2020-07-17  09:45:00   2030          1007             100.0         1917.0   \n",
       "2020-07-20  09:30:00   2037          1008             100.0         1917.0   \n",
       "2020-07-22  09:30:00   2044          1010             100.0         1920.0   \n",
       "2020-07-24  09:30:00   2058          1014             100.0         1922.0   \n",
       "\n",
       "            Akute Fälle  \n",
       "Datum                    \n",
       "2020-03-09           58  \n",
       "2020-03-10           55  \n",
       "2020-03-11           63  \n",
       "2020-03-12           70  \n",
       "2020-03-13           58  \n",
       "2020-03-14           72  \n",
       "2020-03-15          155  \n",
       "2020-03-16          136  \n",
       "2020-03-17          209  \n",
       "2020-03-18          269  \n",
       "2020-03-19          330  \n",
       "2020-03-20          400  \n",
       "2020-03-21          438  \n",
       "2020-03-22          511  \n",
       "2020-03-23          524  \n",
       "2020-03-24          533  \n",
       "2020-03-25          610  \n",
       "2020-03-26          685  \n",
       "2020-03-27          732  \n",
       "2020-03-28          773  \n",
       "2020-03-29          810  \n",
       "2020-03-30          849  \n",
       "2020-03-31          583  \n",
       "2020-04-01          600  \n",
       "2020-04-02          625  \n",
       "2020-04-03          640  \n",
       "2020-04-04          626  \n",
       "2020-04-05          654  \n",
       "2020-04-06          650  \n",
       "2020-04-07          598  \n",
       "...                 ...  \n",
       "2020-05-26           30  \n",
       "2020-05-27           24  \n",
       "2020-05-28           23  \n",
       "2020-05-29           24  \n",
       "2020-06-02           22  \n",
       "2020-06-03           20  \n",
       "2020-06-04           22  \n",
       "2020-06-05           23  \n",
       "2020-06-08           23  \n",
       "2020-06-09           22  \n",
       "2020-06-10           20  \n",
       "2020-06-12           18  \n",
       "2020-06-15           16  \n",
       "2020-06-17           19  \n",
       "2020-06-19           21  \n",
       "2020-06-22           22  \n",
       "2020-06-24           23  \n",
       "2020-06-26           21  \n",
       "2020-06-29           20  \n",
       "2020-07-01           16  \n",
       "2020-07-03           13  \n",
       "2020-07-06           12  \n",
       "2020-07-08           11  \n",
       "2020-07-10            3  \n",
       "2020-07-13           13  \n",
       "2020-07-15           16  \n",
       "2020-07-17           13  \n",
       "2020-07-20           20  \n",
       "2020-07-22           24  \n",
       "2020-07-24           36  \n",
       "\n",
       "[99 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    c19_cases = pd.read_excel(config['Rohdaten']['FileName'], \n",
    "                              sheet_name=config['Rohdaten']['SheetName'], \n",
    "                              index_col=0,\n",
    "                              parse_dates=[0],\n",
    "                              skiprows=[1],\n",
    "                              names=['Uhrzeit', 'Summe', 'Summe Aachen', 'Summe Todesfälle', 'Summe genesen', 'Akute Fälle' ])\n",
    "except FileNotFoundError as err: \n",
    "    log.warning('Error during pd.read_excel(): {0}'.format(err))\n",
    "    # Leere DataFrame für den Start erzeugen\n",
    "    cols = [ 'Uhrzeit', 'Summe', 'Summe Aachen', 'Summe Todesfälle', 'Summe genesen', 'Akute Fälle' ]\n",
    "    c19_cases = pd.DataFrame(columns=cols, index=pd.DatetimeIndex([], name='Datum'))\n",
    "    \n",
    "c19_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenabfrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionen für die Datenabfrage und Extraktion der Rohtexte\n",
    "- `robot_access_allowed()` - Via robots.txt prüfen, ob die Website durch ein Skript abgefragt und verabeitet werden darf\n",
    "- `gather_html()` - Website abfragen und HTML zurückliefern\n",
    "- `gather_text()` - Relevante Texte aus dem von der Website geliefertem HTML extrahieren und zurückliefern\n",
    "\n",
    "*<u>Anmerkungen:</u>  \n",
    "Die Website der Städteregion Aachen verwendet keine `robots.txt`, damit wäre die Funktion `robot_access_allowed()` eigentlich überflüssig. Hier ist sie nur der Vollständigkeit halber definiert.*\n",
    "\n",
    "*Leider unterscheidet sich die HTML-Struktur der aktuellen Meldungen von der des Meldungsarchivs so stark, dass schon an dieser Stelle eine Differenzierung aufgrund des Textes und nicht nur der HTML-Struktur erfolgen muss. Daher wurde das Argument `kind` zur Funktion `gather_html()` hinzugefügt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_user_agent = config['Rohdaten']['UserAgent']\n",
    "\n",
    "def robot_access_allowed(url, user_agent=default_user_agent):\n",
    "    \"\"\"Request robots.txt. If exists, parse robots.txt and return True if scraping by this script is allowed.\"\"\"\n",
    "    \n",
    "    log.debug(\"access_allowed(\" + url + \", \" + user_agent + \")\")\n",
    "    \n",
    "    headers = { 'user-agent': user_agent }\n",
    "    \n",
    "    # Extract root of the website's URL\n",
    "    \n",
    "    # Request robots.txt from root of the website\n",
    "    \n",
    "    # If robots.txt exist, parse content of the file\n",
    "    \n",
    "    return True\n",
    "\n",
    "def gather_html(url, user_agent=default_user_agent):\n",
    "    \"\"\"Request Website from <url> and return the HTML delivered by the Website as text.\"\"\"\n",
    "\n",
    "    log.debug(\"gather_html(\" + url + \", \" + user_agent + \")\")\n",
    "    \n",
    "    # Website abfragen\n",
    "    headers = { 'user-agent': user_agent }\n",
    "    page = requests.get(url)\n",
    "    log.debug(\"gather_html/page.status_code: %d\", page.status_code)\n",
    "    for key, val in page.headers.items():\n",
    "        log.debug(\"gather_html/page.header(%s): %s\", key, val)   \n",
    "    if page.status_code == requests.codes.ALL_OK: # Alles ok\n",
    "        return page.text\n",
    "        \n",
    "    return None\n",
    "\n",
    "def gather_text(html_text):\n",
    "    \"\"\"Extract relevant text content from <html_text> and return dictionary with extracted text for 'Header', 'Abstract', 'Main'.\"\"\"\n",
    "\n",
    "    log.debug(f\"gather_text(%d chars)\", len(html_text))\n",
    "\n",
    "    records = []\n",
    "       \n",
    "    # Relevante Objekte aus geliefertem HTML extrahieren\n",
    "    # - Header\n",
    "    # - Abstract (existiert nur für die aktuellen Meldungen, nicht im Meldungsarchiv)\n",
    "    # - Main\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    divs = soup.select('div.mid-col article > div.textcontent > div')\n",
    "    for div in divs:\n",
    "        # Header erkennen: Nun wenn dieser gefunden wird, macht es Sinn, nachfolgend nach \n",
    "        # 'Abstract'- und 'Main'-Texten zu suchen\n",
    "        header = div.select('h2')\n",
    "        if header:\n",
    "            header_text = next(header[0].stripped_strings)\n",
    "\n",
    "            abstract = div.select('div > div > ul > li')\n",
    "            abstract_text = ''\n",
    "            for a in abstract:\n",
    "                for tx in a.stripped_strings:\n",
    "                    abstract_text += tx\n",
    "\n",
    "            main = div.select('div > p')\n",
    "            main_text = ''\n",
    "            for tx in main[0].stripped_strings:\n",
    "                main_text += tx\n",
    "\n",
    "            records.append({'Header': header_text, 'Abstract': abstract_text, 'Main': main_text })\n",
    "                        \n",
    "    log.debug(\"gather_text: %d records extracted from HTML\", len(records))\n",
    "    \n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionen für die Extraktion der Falldaten aus den Rohtexten\n",
    "In der ersten Version erfolgt die Extraktion der Daten aus den Texten mit Hilfe regulärer Ausdrücke:\n",
    "- Datum/Uhrzeit der Meldung wird aus dem `Header` extrahiert.\n",
    "- Die eigentlichen Daten werden zweimal extrahiert: Einmal aus dem `Abstract` und zum zweiten Mal aus dem `Main`-Text. \n",
    "- Falls sowohl `Abstract` als auch `Main` eingelesen wurden, werden anschließend die extrahierten Daten miteinander verglichen. Nur wenn sie übereinstimmen, wird der Datensatz übernommen.\n",
    "\n",
    "Die für das Parsen der eingelesenen Texte verwendeten regulären Ausdrücke versuchen einerseits, auf Nummer sicher zu gehen, um die richtigen Textstellen für das Einlesen der Zahlen zu treffen, und andererseits einige Freiheitsgrade zuzulassen: Leerzeichen und andere \"White Spaces\" werden von Menschen hin und wieder vergesssen oder mehrfach eingegeben, Textvariationen kommen vor, in denen einzelne Wörter nicht erscheinen oder hinzugefügt werden; und natürlich kommen auch Schreibfehler vor. Die regulären Ausdrücke sind dadurch schon recht unübersichtlich geworden und berücksichtigen dennoch nicht alle Situationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsMeta():\n",
    "    \"\"\"Value class for meta data of news entry.\"\"\"\n",
    "    pass\n",
    "\n",
    "class CaseFigures():\n",
    "    \"\"\"Value class for case figures, extracted from the news entries.\"\"\"\n",
    "    pass\n",
    "\n",
    "def parse_header(header: str) -> NewsMeta:\n",
    "    \"\"\"\n",
    "    Analyse <header> of the news and return date and time of news or None. \n",
    "    \n",
    "    The <header> is expected to have the following format:\n",
    "    \n",
    "    'Aktuelle Lage Stadt und StädteRegion Aachen zum Corona-Virus; Montag, 22. Juni, 10:00 Uhr'\n",
    "    \n",
    "    Variables weekday name, date, and time will be extracted from header. Year assumed to be 2020.\n",
    "    \n",
    "    Args:\n",
    "    header - extracted raw text of header\n",
    "    \n",
    "    Returns:\n",
    "    None - if no matching header found\n",
    "    NewsMeta(weekday_name, day_of_month, month_name, hour, minutes, date, time, datetime)\n",
    "    \"\"\"\n",
    "    \n",
    "    monthnames = [ \"Januar\", \"Februar\", \"März\", \"April\", \"Mai\", \"Juni\", \"Juli\", \"August\", \"September\", \"Oktober\", \"November\", \"Dezember\" ]\n",
    "    \n",
    "    log.debug(\"parse_header(\" + header[:40] + \"...)\")\n",
    "    \n",
    "    pattern = r\"^Aktuelle Lage Stadt und StädteRegion Aachen zum Corona-Virus;\\s*\" \\\n",
    "    \"(Montag|Dienstag|Mittwoch|Donnerstag|Freitag|Samstag|Sonntag),\\s*\" \\\n",
    "    \"([0-9]{1,2})\\.\\s*(Januar|Februar|März|April|Mai|Juni|Juli|August|September|Oktober|November|Dezember),\\s*\" \\\n",
    "    \"([0-9]{1,2}):([0-9]{2})\\s*Uhr.*$\"\n",
    "        \n",
    "    match = re.search(pattern, header)\n",
    "    if match:\n",
    "        meta = NewsMeta()\n",
    "        try:\n",
    "            meta.weekday_name = match.group(1)\n",
    "            meta.day_of_month = int(match.group(2))\n",
    "            meta.month_name = match.group(3)\n",
    "            meta.hour = int(match.group(4))\n",
    "            meta.minutes = int(match.group(5))\n",
    "            meta.date = date(2020, monthnames.index(meta.month_name) + 1, meta.day_of_month)\n",
    "            meta.time = time(meta.hour, meta.minutes)\n",
    "            meta.datetime = datetime.combine(meta.date, meta.time)\n",
    "            log.debug(f\"parse_header/meta.weekday: %s\", meta.weekday_name)        \n",
    "            log.debug(f\"parse_header/meta.day_of_month: %d\", meta.day_of_month)        \n",
    "            log.debug(f\"parse_header/meta.month_name: %s\", meta.month_name)        \n",
    "            log.debug(f\"parse_header/meta.hour: %d\", meta.hour)        \n",
    "            log.debug(f\"parse_header/meta.minutes: %d\", meta.minutes)        \n",
    "            log.debug(f\"parse_header/meta.date: %s\", str(meta.date))        \n",
    "            log.debug(f\"parse_header/meta.time: %s\", str(meta.time))\n",
    "            log.debug(f\"parse_header/meta.datetime: %s\", str(meta.datetime))\n",
    "            return meta\n",
    "        except:\n",
    "            log.warning(\"parse_header() failed parsing news header [1]\")\n",
    "            return None\n",
    "    else: \n",
    "        log.warning(\"parse_header() failed parsing news header [2]\")\n",
    "        return None\n",
    "\n",
    "def parse_cases(kind: str, text: str, pattern_total: str, pattern_recovered: str, pattern_deaths: str, \n",
    "                pattern_active: str) -> CaseFigures:\n",
    "    \"\"\"\n",
    "    Analyse <abstract> or <main> text of the news and return Covid-19 case numbers included therein. \n",
    "  \n",
    "    Args:\n",
    "    kind\n",
    "    text\n",
    "    pattern_total\n",
    "    pattern_recovered\n",
    "    pattern_deaths\n",
    "    pattern_active\n",
    "    \n",
    "    Returns:\n",
    "    None - if text could not be parsed successfully\n",
    "    CaseFigures(total, total_AC, recovered, deaths, active)\n",
    "    \"\"\"\n",
    "    \n",
    "    log.debug(f\"parse_cases(%s, %s)\", kind, text[:80])\n",
    "\n",
    "    figures = CaseFigures()\n",
    "    \n",
    "    # Summe der Corona-Fälle extrahieren\n",
    "    match = re.search(pattern_total, text)\n",
    "    if match:\n",
    "        try:\n",
    "            figures.total = int(match.group(1))\n",
    "            figures.total_AC = int(match.group(2))\n",
    "            log.debug(f\"parse_cases/figures.total: %d\", figures.total)        \n",
    "            log.debug(f\"parse_cases/figures.total_AC: %d\", figures.total_AC)        \n",
    "        except:\n",
    "            log.warning(f\"parse_cases(%s) failed [1]\", kind)\n",
    "            return None\n",
    "    else: \n",
    "        log.warning(f\"parse_cases(%s) failed [2]\", kind)\n",
    "        return None\n",
    "    \n",
    "    # Summe der wieder Genesenen extrahieren\n",
    "    match = re.search(pattern_recovered, text)\n",
    "    if match:\n",
    "        try:\n",
    "            figures.recovered = int(match.group(1))\n",
    "            log.debug(f\"parse_cases/figures.recovered: %d\", figures.recovered)        \n",
    "        except:\n",
    "            log.warning(f\"parse_cases(%s) failed [3]\", kind)\n",
    "            return None\n",
    "    else: \n",
    "        log.warning(f\"parse_cases(%s) failed [4]\", kind)\n",
    "        return None\n",
    "    \n",
    "    # Summe der Corona-Toten extrahieren\n",
    "    match = re.search(pattern_deaths, text)\n",
    "    if match:\n",
    "        try:\n",
    "            figures.deaths = int(match.group(1))\n",
    "            log.debug(f\"parse_cases/figures.deaths: %d\", figures.deaths)        \n",
    "        except:\n",
    "            log.warning(f\"parse_cases(%s) failed [5]\", kind)\n",
    "            return None\n",
    "    else: \n",
    "        log.warning(f\"parse_cases(%s) failed [6]\", kind)\n",
    "        return None\n",
    "    \n",
    "    # Anzahl der aktiven Infektionen extrahieren\n",
    "    match = re.search(pattern_active, text)\n",
    "    if match:\n",
    "        try:\n",
    "            figures.active = int(match.group(1))\n",
    "            log.debug(f\"parse_cases/figures.active: %d\", figures.active)        \n",
    "        except:\n",
    "            log.warning(f\"parse_cases(%s) failed [7]\", kind)\n",
    "            return None\n",
    "    else: \n",
    "        log.warning(f\"parse_cases(%s) failed [8]: %s\", kind, text)\n",
    "        return None\n",
    "\n",
    "    return figures\n",
    "\n",
    "def parse_abstract(abstract: str) -> CaseFigures:\n",
    "    \"\"\"\n",
    "    Analyse <abstract> of the news and return Covid-19 case numbers included in abstract. \n",
    "\n",
    "    The relevant area of the <abstract> is expected to have the following format:\n",
    "    \n",
    "    'Aktuell 1999 bestätigte Coronafälle in der StädteRegion Aachen (davon 994 in der Stadt Aachen). '\n",
    "    '1880 ehemals positiv auf das Corona-Virus getestete Personen sind inzwischen wieder gesund. '\n",
    "    'Bislang 98 Todesfälle. Damit aktuell 21 nachgewiesene Infizierte.'\n",
    "    \n",
    "    Values will be extracted from abstract text. \n",
    "    \n",
    "    Args:\n",
    "    abstract - extracted raw text of abstract\n",
    "    \n",
    "    Returns:\n",
    "    None - if abstract could not be parsed successfully\n",
    "    CaseFigures(total, total_AC, recovered, deaths, active)\n",
    "    \"\"\"\n",
    "    \n",
    "    log.debug(\"parse_abstract(\" + abstract[:40] + \"...)\")\n",
    "    \n",
    "    pattern_total = r\"^Aktuell\\s*([0-9]{1,6})\\s*bestätigte\\s*Coronafälle\\s*in\\s*der\\s*StädteRegion\\s*(?:Aachen)?\\s*\" + \\\n",
    "    r\"[(]davon\\s*([0-9]{1,6})\\s*in\\s*der\\s*Stadt\\s*Aachen[)].*\"\n",
    "    pattern_recovered = r\"([0-9]{1,6})\\s*ehemals\\s*positiv\\s*auf\\s*das\\s*Corona-Virus\\s*getestete\\s*Personen\\s*sind\\s*inzwischen\" + \\\n",
    "    r\"\\s*wieder\\s*gesund.*\"\n",
    "    pattern_deaths = r\"Bislang\\s*([0-9]{1,6})\\s*Todesfälle.*\"\n",
    "    pattern_active = r\"Damit\\s*aktuell\\s*([0-9]{1,6})\\s*nachgewiesene\\s*Infizie.*\"\n",
    "        \n",
    "    return parse_cases(\"Abstract\", abstract, pattern_total, pattern_recovered, pattern_deaths, pattern_active)\n",
    "\n",
    "def parse_main(main: str) -> CaseFigures:\n",
    "    \"\"\"\n",
    "    Analyse <main> text of the news and return Covid-19 case numbers included in main text. \n",
    "    \n",
    "    The relevant area of the <abstract> is expected to have the following format:\n",
    "      \n",
    "    'Es gibt insgesamt in der StädteRegion [nunmehr] 1997 positive Fälle, davon 992 in der Stadt Aachen'\n",
    "    '1876 ehemals positiv auf das Corona-Virus getestete Personen sind inzwischen wieder gesund'\n",
    "    'Die Zahl der gemeldeten Todesfälle liegt [nach wie vor] bei 98'\n",
    "    'Damit sind aktuell 23 Menschen in der StädteRegion nachgewiesen infiziert'\n",
    "\n",
    "    Args:\n",
    "    \n",
    "    Returns:\n",
    "    None - if abstract could not be parsed successfully\n",
    "    CaseFigures(total, total_AC, recovered, deaths, active)\n",
    "    \"\"\"\n",
    "    log.debug(\"parse_main(\" + main[:40] + \"...)\")\n",
    "\n",
    "    pattern_total = r\"Es\\s*gibt\\s*insgesamt\\s*in\\s*der\\s*StädteRegion\\s*(?:nunmehr)?\\s*([0-9]{1,6})\\s*positive\\s*Fälle,\\s*\" + \\\n",
    "    r\"davon\\s*([0-9]{1,6})\\s*in\\s*der\\s*Stadt\\s*Aachen\"\n",
    "    pattern_recovered = r\"([0-9]{1,6})\\s*ehemals\\s*positiv\\s*auf\\s*das\\s*Corona-Virus\\s*getestete\\s*Personen\\s*sind\\s*inzwischen\\s*\" + \\\n",
    "    r\"wieder\\s*gesund\"\n",
    "    pattern_deaths = r\"Die\\s*Zahl\\s*der\\s*gemeldeten\\s*Todesfälle\\s*liegt\\s*(?:nach\\s*wie\\s*vor)?\\s*bei\\s*([0-9]{1,6})\"\n",
    "    pattern_active = r\"Damit\\s*sind\\s*aktuell\\s*([0-9]{1,6})\\s*Menschen\\s*in\\s*der\\s*StädteRegion\\s*(?:Aachen)?\\s*nachgewiesen\\s*infiziert\"\n",
    "    \n",
    "    return parse_cases(\"Main\", main, pattern_total, pattern_recovered, pattern_deaths, pattern_active)\n",
    "\n",
    "def checked_data(meta: str, fig_abstract: str, fig_main: str) -> []:\n",
    "    \"\"\"\n",
    "    Check extracted data for consistency and return valid figures or None.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    if meta != None: # Der Header konnte erfolgreich analysiert werden\n",
    "        a, m = fig_abstract, fig_main\n",
    "        if (a != None) and (m != None): # Sowohl Abstract als auch Main konnten erfolgreich analysiert werden\n",
    "            if (m.total == a.total) and (m.deaths == a.deaths) and (m.recovered == a.recovered) and \\\n",
    "               (m.active == a.active):\n",
    "                if m.active == 0:\n",
    "                    m.active = m.total - m.deaths - m.recovered\n",
    "                if m.total - m.deaths - m.recovered == m.active:\n",
    "                    return [ meta.date, meta.time, m.total, m.total_AC, m.deaths, m.recovered, m.active ]\n",
    "        elif m != None: # Mindestens Main konnte erfolgreich analysiert werden\n",
    "            if m.active == 0:\n",
    "                m.active = m.total - m.deaths - m.recovered\n",
    "            if m.total - m.deaths - m.recovered == m.active:\n",
    "                return [ meta.date, meta.time, m.total, m.total_AC, m.deaths, m.recovered, m.active ]\n",
    "    return None\n",
    "\n",
    "def fill_dataframe_from_text(text_records: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyse <text_records> and return Pandas dataframe with parsed Covid-19 case numbers. \n",
    "    \n",
    "    Args:\n",
    "    text_records\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame - \n",
    "    \"\"\"\n",
    "    log.debug(f\"fill_dataframe_from_text(%d records)\", len(text_records))\n",
    "\n",
    "    fig = []\n",
    "    date = []\n",
    "    \n",
    "    for tr in text_records:\n",
    "        meta = parse_header(tr['Header'])\n",
    "        fig_abstract = parse_abstract(tr['Abstract'])\n",
    "        fig_main = parse_main(tr['Main'])\n",
    "        \n",
    "        rec = checked_data(meta, fig_abstract, fig_main)\n",
    "        if rec:\n",
    "            date.append(rec[0])\n",
    "            fig.append(rec[1:])\n",
    "\n",
    "    if fig.count:\n",
    "        cols = [ 'Uhrzeit', 'Summe', 'Summe Aachen', 'Summe Todesfälle', 'Summe genesen', 'Akute Fälle' ]\n",
    "        df = pd.DataFrame(np.array(fig), columns=cols, index=pd.DatetimeIndex(date, name='Datum')).sort_index()\n",
    "        return df\n",
    "    \n",
    "    return pd.DataFrame() # Leer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenabfrage durchführen\n",
    "1. Datum des letzten Datensatzes in der Excel-Datei ermitteln und mit aktuellem Datum vergleichen. \n",
    "2. Wenn mindestens 1 Tag seit der letzten Datenabfrage vergangen ist, neue Abfrage durchführen.\n",
    "3. Von der Website gelieferte Rohtexte auswerten und Fallzahlen extrahieren\n",
    "4. Extrahierte Fallzahlen auf Konsistenz prüfen\n",
    "5. Geprüfte Fallzahlen zu neuem DataFrame hinzufügen\n",
    "6. Den neuen mit dem existierendem DataFrame zusammenführen\n",
    "7. Die zusammengeführten Daten speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "new_request = (c19_cases.size == 0) or (date.today() >= (date.fromtimestamp(c19_cases.index.max().timestamp()) + timedelta(days=1)))\n",
    "\n",
    "url = config['Rohdaten']['SourceURLDefault']\n",
    "if new_request:\n",
    "    log.info(\"New request initiated\")\n",
    "    if not html_payload:\n",
    "        if robot_access_allowed(url):\n",
    "            html_payload = gather_html(url)\n",
    "\n",
    "    if html_payload:\n",
    "        records = gather_text(html_payload)\n",
    "\n",
    "    if records.count:\n",
    "        new_cases = fill_dataframe_from_text(records)\n",
    "\n",
    "    if not new_cases.empty:\n",
    "        # Nur Zeilen mit neuerem Datum hinzufügen\n",
    "        merged_cases = pd.concat([c19_cases, new_cases[new_cases.index > c19_cases.index[-1]]], join='outer')\n",
    "\n",
    "    merged_cases.to_excel(config['Rohdaten']['FileName'], \n",
    "                          sheet_name=config['Rohdaten']['SheetName'], index_label='Datum')\n",
    "\n",
    "    merged_cases\n",
    "else:\n",
    "    log.info(\"No new request required\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
